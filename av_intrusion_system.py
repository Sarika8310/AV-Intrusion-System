# -*- coding: utf-8 -*-
"""AV Intrusion System

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xkLuQQm3STDmIc6k6p2C-pfJe-8fJ7Fb
"""

# üöó PHASE 1 ‚Äì Final Version (Cleaned for DoS + RPM datasets)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# ‚úÖ Step 1: Load CSVs
dos_path = "/content/DoS_dataset.csv"
rpm_path = "/content/RPM_dataset.csv"

df_dos = pd.read_csv(dos_path, header=None)
df_rpm = pd.read_csv(rpm_path, header=None)

# ‚úÖ Step 2: Add correct column headers (12 total)
columns = ['Time', 'ID', 'Len', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'Class']
df_dos.columns = columns
df_rpm.columns = columns

# ‚úÖ Step 3: Label datasets manually
df_dos['Class'] = 1  # Attack
df_rpm['Class'] = 0  # Normal

# ‚úÖ Step 4: Merge datasets
df = pd.concat([df_rpm, df_dos], ignore_index=True)

# ‚úÖ Step 5: Drop 'Time' column (not useful)
df = df.drop(['Time'], axis=1)

# ‚úÖ Step 6: Convert hex strings to integers wherever possible
for col in df.columns:
    if col != 'Class':
        df[col] = df[col].apply(
            lambda x: int(str(x), 16) if isinstance(x, str) and all(c in '0123456789abcdefABCDEF' for c in str(x)) else x
        )

# ‚úÖ Step 7: Clean up ‚Äî convert all to numeric, drop bad rows
X = df.drop('Class', axis=1)
X = X.apply(pd.to_numeric, errors='coerce')  # invalid strings -> NaN
X = X.dropna()  # drop rows with NaN
y = df['Class'].loc[X.index]  # match labels

# ‚úÖ Step 8: Normalize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ‚úÖ Step 9: Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y.reset_index(drop=True), test_size=0.2, random_state=42
)

print("‚úÖ Phase 1 complete ‚Äî data is cleaned, encoded, scaled, and split.")
print("üü¢ X_train shape:", X_train.shape)
print("üü¢ y_train value counts:\n", y_train.value_counts())

# üöó PHASE 2 ‚Äì Random Forest Model

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import joblib  # for saving the model

# ‚úÖ Step 1: Train model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
rf_model.fit(X_train, y_train)

# ‚úÖ Step 2: Predictions
y_pred = rf_model.predict(X_test)

# ‚úÖ Step 3: Evaluation
acc = accuracy_score(y_test, y_pred)
print("‚úÖ Accuracy:", round(acc * 100, 2), "%")

print("\nüìä Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

print("\nüìÑ Classification Report:")
print(classification_report(y_test, y_pred))

# ‚úÖ Step 4: Save model (optional)
joblib.dump(rf_model, "random_forest_car_model.pkl")
print("‚úÖ Model saved as random_forest_car_model.pkl")

import joblib

# Save model and scaler
joblib.dump(model, "random_forest_car_model.pkl")
joblib.dump(scaler, "scaler.pkl")

from google.colab import files
files.download("random_forest_car_model.pkl")
files.download("scaler.pkl")

import pandas as pd
import time
import joblib
from sklearn.preprocessing import StandardScaler

# Step 1: Load the saved model
model = joblib.load("/content/random_forest_car_model.pkl")

# Step 2: Reuse and fit the scaler (with X_train from Phase 1)
scaler = StandardScaler()
scaler.fit(X_train)  # Make sure X_train is still in memory

# Step 3: Sample 10 random rows from your full DataFrame (df)
sample = df.sample(10).drop(columns=['Class'])

# Step 4: Convert hex-like values to integers (in case you reloaded df)
for col in sample.columns:
    sample[col] = sample[col].apply(lambda x: int(str(x), 16)
                                    if isinstance(x, str) and all(c in '0123456789abcdefABCDEF' for c in str(x))
                                    else x)

# Step 5: Scale the sample
sample_scaled = scaler.transform(sample)

# Step 6: Simulate real-time prediction
print("üöó Real-Time Intrusion Detection Simulation Started...\n")
for i, row in enumerate(sample_scaled):
    time.sleep(1)  # Simulate time delay like real CAN bus signals
    pred = model.predict([row])[0]
    status = "üö® ATTACK DETECTED!" if pred == 1 else "‚úÖ Normal Signal"
    print(f"[Frame {i+1}] Status: {status}")

import pandas as pd
import time
import joblib
from datetime import datetime
from sklearn.preprocessing import StandardScaler

# Load trained model
model = joblib.load("/content/random_forest_car_model.pkl")

# Reuse scaler
scaler = StandardScaler()
scaler.fit(X_train)

# Sample 15 rows for simulation
sample = df.sample(15).drop(columns=['Class'])

# Convert hex-like to int
for col in sample.columns:
    sample[col] = sample[col].apply(lambda x: int(str(x), 16)
                                    if isinstance(x, str) and all(c in '0123456789abcdefABCDEF' for c in str(x))
                                    else x)

# Scale input
sample_scaled = scaler.transform(sample)

# Prepare logging
log = []

print("üöó Intrusion Detection System with Logging Started...\n")

for i, row in enumerate(sample_scaled):
    time.sleep(1)
    prediction = model.predict([row])[0]
    probability = model.predict_proba([row])[0][prediction]  # Confidence score

    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    status = "ATTACK" if prediction == 1 else "NORMAL"
    confidence = round(probability * 100, 2)

    print(f"[{timestamp}] Frame {i+1} ‚ûú {status} ({confidence}%)")

    # Log this frame
    log.append({
        "Timestamp": timestamp,
        "Frame": i + 1,
        "Status": status,
        "Confidence (%)": confidence
    })

# Save to CSV
log_df = pd.DataFrame(log)
log_df.to_csv("intrusion_log.csv", index=False)
print("\n‚úÖ All detection results saved to 'intrusion_log.csv'")

pip install streamlit



code = '''
import streamlit as st
import pandas as pd
import joblib
from sklearn.preprocessing import StandardScaler

# Page settings
st.set_page_config(page_title="AV Intrusion Detector", layout="centered")
st.title("üöó Smart Car Intrusion Detection")
st.markdown("Upload CAN bus data to detect possible intrusions in real time.")

# Load model
model = joblib.load("random_forest_car_model.pkl")

# Simulate the training scaler
# (Optional: You can save & load scaler with joblib too if needed)
scaler = StandardScaler()
example_data = pd.read_csv("RPM_dataset.csv", header=None)
example_data.columns = ['Time', 'ID', 'Len', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'Class']
example_data = example_data.drop(columns=['Time', 'Class'], errors='ignore')

# Hex conversion for training data
for col in example_data.columns:
    example_data[col] = example_data[col].apply(
        lambda x: int(str(x), 16) if isinstance(x, str) and all(c in '0123456789abcdefABCDEF' for c in str(x)) else x
    )

example_data = example_data.apply(pd.to_numeric, errors='coerce')
example_data = example_data.dropna()
scaler.fit(example_data)

# Upload CSV
uploaded_file = st.file_uploader("üì§ Upload CAN Bus CSV File", type=["csv"])

if uploaded_file:
    df = pd.read_csv(uploaded_file)

    # Clean incoming data
    df = df.drop(columns=[col for col in ['Time', 'Class'] if col in df.columns], errors='ignore')
    df = df.dropna()

    for col in df.columns:
        df[col] = df[col].apply(
            lambda x: int(str(x), 16) if isinstance(x, str) and all(c in '0123456789abcdefABCDEF' for c in str(x)) else x
        )

    df = df.apply(pd.to_numeric, errors='coerce')
    df = df.dropna()

    # Scale & Predict
    df_scaled = scaler.transform(df)
    predictions = model.predict(df_scaled)
    confidences = model.predict_proba(df_scaled)

    df['Status'] = ['ATTACK' if p == 1 else 'NORMAL' for p in predictions]
    df['Confidence (%)'] = [round(max(c) * 100, 2) for c in confidences]

    st.success("‚úÖ Intrusion Detection Complete")
    st.dataframe(df)

    # Download option
    result_csv = df.to_csv(index=False).encode('utf-8')
    st.download_button("‚¨áÔ∏è Download Detection Results", result_csv, "intrusion_results.csv", "text/csv")

else:
    st.info("Upload a CSV file to begin.")

'''

# üîΩ Save as app.py
with open("app.py", "w") as f:
    f.write(code)

# üîΩ Download app.py to your computer
from google.colab import files
files.download("app.py")